# üöÄ Quick Start Guide - AI Pictionary

Guide rapide pour utiliser l'application AI Pictionary en production ou d√©velopper localement.

---

## ‚ú® Quick Start - Production (0 minutes)

### Option 1: Utiliser l'Application D√©ploy√©e (Recommand√©)

**Acc√®s instantan√© :**

üåê **Application Live:** [https://ai-pictionary-4f8f2.web.app](https://ai-pictionary-4f8f2.web.app)

**Caract√©ristiques :**
- ‚úÖ Aucune installation n√©cessaire
- ‚úÖ Backend d√©ploy√© sur Google Cloud Run (europe-west1)
- ‚úÖ Frontend h√©berg√© sur Firebase Hosting (CDN global)
- ‚úÖ Mod√®le CNN pr√©-entra√Æn√© (91-93% accuracy)
- ‚úÖ 20 cat√©gories disponibles (apple, sun, tree, house, car, etc.)
- ‚úÖ Gratuit (dans les limites du free tier)

**Tester l'API Backend :**

```bash
# V√©rifier la sant√© du backend
curl https://ai-pictionary-backend-1064461234232.europe-west1.run.app/health

# R√©ponse attendue:
{
  "status": "healthy",
  "model_version": "v1.0.0",
  "model_loaded": true,
  "categories_count": 20
}
```

**URLs Production :**

| Service | URL | Statut |
|---------|-----|--------|
| Frontend | https://ai-pictionary-4f8f2.web.app | ‚úÖ Live |
| Backend API | https://ai-pictionary-backend-1064461234232.europe-west1.run.app | ‚úÖ Live |
| Health Check | [/health](https://ai-pictionary-backend-1064461234232.europe-west1.run.app/health) | ‚úÖ Healthy |
| API Docs (Swagger) | [/docs](https://ai-pictionary-backend-1064461234232.europe-west1.run.app/docs) | üìö Available |

**Performances Production :**
- **Latence frontend :** <2s (chargement initial)
- **Latence backend (warm) :** 113-327ms
- **Cold start :** 2-5s (apr√®s 15min d'inactivit√©)
- **Inf√©rence CNN :** 8-12ms
- **Co√ªt :** $0/mois (100 utilisateurs dans le free tier)

---

## üõ†Ô∏è Quick Start - D√©veloppement Local (70 minutes)

### Quand utiliser le d√©veloppement local ?

- ‚úÖ Modifier le code frontend/backend
- ‚úÖ Entra√Æner un nouveau mod√®le
- ‚úÖ Tester des changements avant d√©ploiement
- ‚úÖ D√©velopper de nouvelles fonctionnalit√©s
- ‚úÖ Debugger l'application

### Pr√©requis
- Python 3.8+
- Node.js 16+
- ~4GB d'espace disque
- Connexion internet

### √âtape 1 : T√©l√©charger le Dataset (20-30 min)

```bash
cd ml-training
python scripts/download_dataset.py
```

**Note :** Le t√©l√©chargement s'ex√©cute en arri√®re-plan. Passez √† l'√©tape suivante pendant ce temps.

### √âtape 2 : Installer les D√©pendances

**Backend :**
```bash
cd backend
pip install -r requirements.txt
```

**Frontend :**
```bash
cd frontend
npm install
```

### √âtape 3 : Pr√©traiter le Dataset (10 min)

```bash
cd ml-training
python scripts/preprocess_dataset.py
```

**R√©sultat attendu :** Fichier `data/processed/quickdraw_20cat.h5` (~400MB)

### √âtape 4 : Entra√Æner le Mod√®le (30 min)

```bash
cd ml-training
jupyter notebook notebooks/train_model.ipynb
```

**Instructions :**
1. Ouvrir le notebook dans le navigateur
2. Menu ‚Üí "Cell" ‚Üí "Run All"
3. Attendre la fin de l'entra√Ænement (15 epochs)
4. Le mod√®le sera sauvegard√© dans `backend/models/quickdraw_v1.0.0.h5`

### √âtape 5 : Lancer l'Application

**Terminal 1 - Backend :**
```bash
cd backend
uvicorn main:app --reload
```

**Terminal 2 - Frontend :**
```bash
cd frontend
npm start
```

### √âtape 6 : Tester

1. Ouvrir http://localhost:3000
2. Dessiner sur le canvas
3. Voir les pr√©dictions en temps r√©el !

---

## üß™ Test d'Int√©gration

### Test de l'Application Production

**V√©rifier que l'application production fonctionne :**

```bash
# Backend health check
curl https://ai-pictionary-backend-1064461234232.europe-west1.run.app/health

# R√©sultat attendu:
{
  "status": "healthy",
  "model_version": "v1.0.0",
  "model_loaded": true,
  "categories_count": 20
}

# Frontend (ouvrir dans le navigateur)
open https://ai-pictionary-4f8f2.web.app
```

### Test de l'Application Locale

V√©rifier que tous les composants locaux fonctionnent :

```bash
python test_integration.py
```

**R√©sultat attendu :**
```
‚úÖ PASSED  Dataset
‚úÖ PASSED  Model
‚úÖ PASSED  Backend Health (localhost:8000)
‚úÖ PASSED  Frontend (localhost:3000)
‚úÖ PASSED  Prediction

üéâ All systems operational!
```

---

## üìö Architecture Simplifi√©e

### Production (D√©ploy√©)

```
         USERS (Global)
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Firebase Hosting (CDN)     ‚îÇ
‚îÇ  ai-pictionary-4f8f2.web.app‚îÇ
‚îÇ  React SPA (80KB gzipped)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ HTTPS
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Google Cloud Run           ‚îÇ
‚îÇ  (europe-west1)             ‚îÇ
‚îÇ  FastAPI + TensorFlow       ‚îÇ
‚îÇ  Docker (500MB image)       ‚îÇ
‚îÇ  Scale: 0-10 instances      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Firebase Services          ‚îÇ
‚îÇ  - Auth (Google, Email)     ‚îÇ
‚îÇ  - Firestore (NoSQL)        ‚îÇ
‚îÇ  - Storage (Objects)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### D√©veloppement Local

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      HTTP/REST       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   React     ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  ‚îÇ  FastAPI    ‚îÇ
‚îÇ   Frontend  ‚îÇ   POST /predict      ‚îÇ  Backend    ‚îÇ
‚îÇ  (Port 3000)‚îÇ                      ‚îÇ (Port 8000)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                                     ‚îÇ
      ‚îÇ                                     ‚îÇ
      ‚ñº                                     ‚ñº
  Canvas 280x280                    TensorFlow Model
  Debounce 500ms                    quickdraw_v1.0.0.h5
                                    (50K params, 5ms)
                                    
  Firebase SDK ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Production Firebase
  (connects to cloud)                           (Auth, Firestore, Storage)
```

---

## üéØ Workflow Utilisateur

1. **Dessiner** sur canvas (280x280px)
2. **Attendre 500ms** (debounce automatique)
3. **API appelle** `/predict` avec image base64
4. **Backend** :
   - Pr√©traite l'image (centroid crop, normalize)
   - Ex√©cute le mod√®le CNN
   - Retourne top-3 pr√©dictions
5. **Frontend affiche** :
   - üü¢ Vert si confiance >85%
   - üü° Jaune si 70-85%
   - üî¥ Rouge si <70% ‚Üí Modal de correction

---

## üêõ D√©pannage

### Backend : "Model not loaded"
```bash
# V√©rifier que le mod√®le existe
ls -lh backend/models/quickdraw_v1.0.0.h5

# Si absent, entra√Æner le mod√®le
cd ml-training
jupyter notebook notebooks/train_model.ipynb
```

### Frontend : "Backend offline"
```bash
# D√©marrer le backend
cd backend
uvicorn main:app --reload

# V√©rifier le health check
curl http://localhost:8000/health
```

### Dataset : T√©l√©chargement lent
```bash
# V√©rifier la progression
cd ml-training/data/raw
ls -lh *.npy | wc -l  # Devrait afficher 20
```

### Port d√©j√† utilis√©
```bash
# Backend (port 8000)
lsof -ti:8000 | xargs kill -9

# Frontend (port 3000)
lsof -ti:3000 | xargs kill -9
```

---

## üìä M√©triques de Performance

| M√©trique | Valeur | Note |
|----------|--------|------|
| Taille mod√®le | 140KB | Tr√®s l√©ger |
| Param√®tres | 35K | Simple CNN |
| Inf√©rence | 5ms | Temps r√©el |
| Accuracy cible | 91-93% | Sur test set |
| Debounce | 500ms | UX optimis√©e |
| Dataset | 1.4M images | 20 cat√©gories |

---

## üéì Cat√©gories Disponibles (20)

```
apple, sun, tree, house, car,
cat, fish, star, umbrella, flower,
moon, airplane, bicycle, clock, eye,
cup, shoe, cloud, lightning, smiley_face
```

---

## üîÑ Workflow de D√©veloppement

### Mode D√©veloppement Local
```bash
# Terminal 1
cd backend && uvicorn main:app --reload

# Terminal 2
cd frontend && npm start
```

### Mode Production (Local Build)
```bash
# Build frontend
cd frontend && npm run build

# Test production build locally
npx serve -s build
```

---

## üöÄ D√©ploiement Production

### Pr√©requis

1. **Google Cloud SDK**
   ```bash
   # Installation (macOS/Linux)
   curl https://sdk.cloud.google.com | bash
   exec -l $SHELL
   
   # Authentification
   gcloud auth login
   gcloud config set project ai-pictionary-4f8f2
   ```

2. **Firebase CLI**
   ```bash
   npm install -g firebase-tools
   firebase login
   ```

### D√©ployer le Backend (Cloud Run)

```bash
cd backend

# Activer les APIs n√©cessaires
gcloud services enable run.googleapis.com \
  containerregistry.googleapis.com \
  cloudbuild.googleapis.com

# D√©ployer
gcloud run deploy ai-pictionary-backend \
  --source . \
  --region europe-west1 \
  --memory 1Gi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 10 \
  --timeout 60s \
  --allow-unauthenticated \
  --env-vars-file env.yaml

# V√©rifier
curl https://ai-pictionary-backend-1064461234232.europe-west1.run.app/health
```

**Fichier `backend/env.yaml` requis :**

```yaml
MODEL_VERSION: "v1.0.0"
CATEGORIES: "apple,sun,tree,house,car,cat,fish,star,umbrella,flower,moon,airplane,bicycle,clock,eye,cup,shoe,cloud,lightning,smiley_face"
CORS_ORIGINS: "http://localhost:3000,https://ai-pictionary-4f8f2.web.app,https://ai-pictionary-4f8f2.firebaseapp.com"
```

### D√©ployer le Frontend (Firebase Hosting)

```bash
cd frontend

# Cr√©er .env.production avec l'URL Cloud Run
echo "REACT_APP_API_BASE_URL=https://ai-pictionary-backend-1064461234232.europe-west1.run.app" >> .env.production

# Ajouter config Firebase
cat >> .env.production << EOF
REACT_APP_FIREBASE_API_KEY=your_api_key
REACT_APP_FIREBASE_AUTH_DOMAIN=ai-pictionary-4f8f2.firebaseapp.com
REACT_APP_FIREBASE_PROJECT_ID=ai-pictionary-4f8f2
REACT_APP_FIREBASE_STORAGE_BUCKET=ai-pictionary-4f8f2.appspot.com
REACT_APP_FIREBASE_MESSAGING_SENDER_ID=your_sender_id
REACT_APP_FIREBASE_APP_ID=your_app_id
EOF

# Build
npm run build

# D√©ployer
firebase use ai-pictionary-4f8f2
firebase deploy --only hosting

# V√©rifier
open https://ai-pictionary-4f8f2.web.app
```

### Fichiers de Configuration Requis

**`firebase.json` (racine du projet) :**

```json
{
  "hosting": {
    "public": "frontend/build",
    "ignore": ["firebase.json", "**/.*", "**/node_modules/**"],
    "rewrites": [
      {
        "source": "**",
        "destination": "/index.html"
      }
    ],
    "headers": [
      {
        "source": "**/*.@(jpg|jpeg|gif|png|svg|webp)",
        "headers": [{"key": "Cache-Control", "value": "max-age=31536000"}]
      },
      {
        "source": "**/*.@(js|css)",
        "headers": [{"key": "Cache-Control", "value": "max-age=31536000"}]
      }
    ]
  }
}
```

**`.firebaserc` (racine du projet) :**

```json
{
  "projects": {
    "default": "ai-pictionary-4f8f2"
  }
}
```

**`backend/Dockerfile` :**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    TF_CPP_MIN_LOG_LEVEL=2 \
    PORT=8080

RUN apt-get update && apt-get install -y libgomp1 && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY main.py .
COPY models/ ./models/
COPY serviceAccountKey.json .

EXPOSE 8080

CMD exec uvicorn main:app --host 0.0.0.0 --port ${PORT} --workers 1
```

### Monitoring

```bash
# Logs Cloud Run
gcloud logging read "resource.type=cloud_run_revision" --limit 50

# Logs Firebase Hosting
firebase hosting:channel:list

# M√©triques Cloud Run
gcloud run services describe ai-pictionary-backend --region europe-west1
```

---

## üìö Documentation Compl√®te

- **Backend API :** `backend/README.md`
- **Frontend :** `frontend/README.md`
- **ML Training :** `ml-training/README.md`
- **Firebase Setup :** `docs/firebase_setup.md`
- **Data Pipeline :** `docs/data_pipeline.md`
- **Defense Justifications :** `docs/defense_justifications.md`

---

## ‚è±Ô∏è Temps Estim√© Total

| √âtape | Dur√©e | Parall√©lisable |
|-------|-------|----------------|
| T√©l√©chargement dataset | 20-30 min | ‚úÖ (pendant installation) |
| Installation d√©pendances | 5 min | ‚úÖ |
| Pr√©traitement dataset | 10 min | ‚ùå |
| Entra√Ænement mod√®le | 30 min | ‚ùå |
| Test application | 5 min | ‚ùå |
| **TOTAL** | **~70 min** | |

**Astuce :** Lancez le t√©l√©chargement du dataset en premier, puis installez les d√©pendances pendant ce temps.

---

## ‚úÖ Checklist Avant D√©fense

### Production (Recommand√©)
- [ ] Application production accessible (https://ai-pictionary-4f8f2.web.app)
- [ ] Backend health check OK (https://ai-pictionary-backend-*.run.app/health)
- [ ] Pr√©dictions en temps r√©el fonctionnelles
- [ ] Modal de correction appara√Æt (<85% confiance)
- [ ] Documentation de d√©fense lue (defense_justifications.md)
- [ ] Architecture Cloud Run + Firebase Hosting comprise
- [ ] Co√ªts production document√©s ($0/mois pour 100 DAU)

### D√©veloppement Local (Optionnel)
- [ ] Dataset t√©l√©charg√© (20 cat√©gories)
- [ ] Dataset pr√©trait√© (quickdraw_20cat.h5)
- [ ] Mod√®le entra√Æn√© (quickdraw_v1.0.0.h5)
- [ ] Backend fonctionne (curl http://localhost:8000/health)
- [ ] Frontend fonctionne (http://localhost:3000)
- [ ] Pr√©dictions en temps r√©el test√©es
- [ ] Modal de correction test√©
- [ ] Firebase configur√©

---

## üéØ Prochaines √âtapes (Phase 2)

### Fonctionnalit√©s √† D√©velopper

1. **Active Learning Pipeline** (2-3 jours)
   - Script retrain_pipeline.py
   - R√©cup√©ration corrections Firestore (>500 labels)
   - Fine-tuning automatis√© (freeze conv layers, LR=0.0001)
   - D√©ploiement nouveau mod√®le sur Cloud Run
   - Trigger: Cloud Scheduler ou manuel

2. **Modes Multijoueurs** (3-4 jours)
   - **Race mode** : Premier √† 85% confiance gagne
   - **Guessing game** : Joueur dessine, autres devinent
   - Firestore real-time listeners (onSnapshot)
   - Lobby system + scoring

3. **Am√©liorations Production** (2-3 jours)
   - CI/CD avec GitHub Actions
   - Monitoring Firebase Analytics
   - Cloud Run min-instances=1 (optionnel, +$5/mois)
   - Cache optimis√© frontend
   - Error tracking (Sentry)

### Timeline Estim√©e
- **Semaine 1 (Jan 15-22)** : Active Learning
- **Semaine 2-3 (Jan 22-Feb 5)** : Multiplayer modes
- **Semaine 4 (Feb 5-13)** : Production improvements + tests finaux

### Ressources

- **Architecture Cloud :** docs/defense_justifications.md (section Cloud Run)
- **Firebase Config :** docs/firebase_setup.md
- **Data Pipeline :** docs/data_pipeline.md
- **Backend API :** backend/README.md
- **Frontend Components :** frontend/README.md

---

**Questions ? Consultez `docs/defense_justifications.md` pour toutes les justifications techniques !**
