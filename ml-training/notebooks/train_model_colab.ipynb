{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-markdown",
   "metadata": {},
   "source": [
    "# üé® AI Pictionary - CNN Model Training (Colab Version)\n",
    "\n",
    "**Quick Draw Dataset Classification with TensorFlow/Keras**\n",
    "\n",
    "Ce notebook est adapt√© pour tourner sur **Google Colab**. Il t√©l√©charge automatiquement les donn√©es brutes depuis les serveurs de Google, les traite, entra√Æne le mod√®le et vous permet de t√©l√©charger le fichier `.h5` final.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-colab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚öôÔ∏è 1. Configuration de l'environnement Colab\n",
    "import os\n",
    "\n",
    "# Cr√©ation de l'arborescence de dossiers n√©cessaire\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"backend/models\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Dossiers cr√©√©s : logs/, backend/models/, data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2Ô∏è‚É£ Import des Librairies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data-colab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3Ô∏è‚É£ T√©l√©chargement et Pr√©paration des Donn√©es\n",
    "# Cette cellule remplace le chargement HDF5 local.\n",
    "# Elle t√©l√©charge les fichiers .npy directement depuis Google Cloud.\n",
    "\n",
    "# Liste de 20 cat√©gories pour la d√©mo\n",
    "CATEGORIES = [\n",
    "    \"apple\", \"banana\", \"baseball\", \"book\", \"bucket\",\n",
    "    \"camera\", \"car\", \"clock\", \"cloud\", \"cup\",\n",
    "    \"door\", \"eye\", \"face\", \"fan\", \"flower\",\n",
    "    \"ladder\", \"lightning\", \"star\", \"sword\", \"tree\"\n",
    "]\n",
    "NUM_CLASSES = len(CATEGORIES)\n",
    "MAX_SAMPLES_PER_CLASS = 12000 # Limite pour √©viter de saturer la RAM Colab\n",
    "\n",
    "print(f\"üì• T√©l√©chargement des donn√©es pour {NUM_CLASSES} cat√©gories...\")\n",
    "base_url = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/\"\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for idx, category in enumerate(CATEGORIES):\n",
    "    # Gestion des espaces dans les noms de fichiers url (ex: ice cream)\n",
    "    filename = category.replace(\" \", \"%20\") + \".npy\"\n",
    "    url = base_url + filename\n",
    "    local_path = f\"data/{category}.npy\"\n",
    "    \n",
    "    if not os.path.exists(local_path):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, local_path)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur t√©l√©chargement {category}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Charger les donn√©es\n",
    "    data = np.load(local_path)\n",
    "    # On garde seulement un sous-ensemble pour la m√©moire\n",
    "    data = data[:MAX_SAMPLES_PER_CLASS] \n",
    "    \n",
    "    X_data.append(data)\n",
    "    y_data.append(np.full(data.shape[0], idx))\n",
    "    print(f\"   ‚úÖ {category}: {data.shape[0]} images charg√©es\")\n",
    "\n",
    "# Concat√©nation\n",
    "X = np.concatenate(X_data, axis=0)\n",
    "y = np.concatenate(y_data, axis=0)\n",
    "\n",
    "# Normalisation [0, 1] et Reshape (N, 28, 28, 1)\n",
    "print(\"\\nüîÑ Normalisation et Reshape...\")\n",
    "X = X.astype('float32') / 255.0\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Split Train/Val/Test (80% / 10% / 10%)\n",
    "print(\"‚úÇÔ∏è  Splitting dataset...\")\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "IMAGE_SHAPE = (28, 28, 1)\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_cat = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val_cat = to_categorical(y_val, NUM_CLASSES)\n",
    "y_test_cat = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset pr√™t !\")\n",
    "print(f\"   Train: {X_train.shape} - Label shape: {y_train_cat.shape}\")\n",
    "print(f\"   Val:   {X_val.shape}\")\n",
    "print(f\"   Test:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4Ô∏è‚É£ Visualisation des √©chantillons\n",
    "# Display random samples (one per category)\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "fig.suptitle('Sample Images from Each Category', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, category in enumerate(CATEGORIES):\n",
    "    if i >= 20: break # Safety check\n",
    "    # Find first image of this category in train set\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    \n",
    "    # Plot image\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(X_train[idx].squeeze(), cmap='gray')\n",
    "    ax.set_title(category, fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5Ô∏è‚É£ Architecture CNN Simple\n",
    "# Build model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=IMAGE_SHAPE),\n",
    "    \n",
    "    # Conv Block 1\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", name=\"conv2d_1\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), name=\"maxpool_1\"),\n",
    "    \n",
    "    # Conv Block 2\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", name=\"conv2d_2\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), name=\"maxpool_2\"),\n",
    "    \n",
    "    # Head\n",
    "    layers.Flatten(name=\"flatten\"),\n",
    "    layers.Dropout(0.5, name=\"dropout\"),\n",
    "    layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"output\")\n",
    "], name=\"QuickDraw_SimpleCNN\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Visualize model architecture (Chemin adapt√© pour Colab)\n",
    "keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"logs/model_architecture.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    dpi=150\n",
    ")\n",
    "print(\"‚úÖ Architecture sauvegard√©e dans logs/model_architecture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compile-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6Ô∏è‚É£ Compilation\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "print(\"‚úÖ Mod√®le compil√© avec Adam & Categorical Crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7Ô∏è‚É£ Entra√Ænement\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 15\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=3, restore_best_weights=True, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='logs/best_model.h5', # Chemin adapt√©\n",
    "        monitor='val_accuracy', save_best_only=True, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001, verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"üöÄ D√©marrage de l'entra√Ænement sur {len(X_train):,} images...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val_cat),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 8Ô∏è‚É£ Historique d'entra√Ænement\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Train Acc')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Val Acc')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].legend()\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.savefig('logs/training_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 9Ô∏è‚É£ √âvaluation sur le Test Set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"\\nüéØ Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"üéØ Test Loss:     {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üîü Matrice de Confusion\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('logs/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1Ô∏è‚É£1Ô∏è‚É£ Sauvegarde et M√©tadonn√©es\n",
    "import json\n",
    "\n",
    "MODEL_VERSION = \"v1.0.0\"\n",
    "# Chemins adapt√©s pour Colab\n",
    "MODEL_SAVE_PATH = f\"backend/models/quickdraw_{MODEL_VERSION}.h5\"\n",
    "METADATA_PATH = f\"backend/models/quickdraw_{MODEL_VERSION}_metadata.json\"\n",
    "\n",
    "# Save Model\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"‚úÖ Mod√®le sauvegard√© : {MODEL_SAVE_PATH}\")\n",
    "\n",
    "# Save Metadata\n",
    "metadata = {\n",
    "    \"version\": MODEL_VERSION,\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "    \"test_accuracy\": float(test_accuracy),\n",
    "    \"categories\": CATEGORIES,\n",
    "    \"num_classes\": NUM_CLASSES\n",
    "}\n",
    "\n",
    "with open(METADATA_PATH, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"‚úÖ M√©tadonn√©es sauvegard√©es : {METADATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚¨áÔ∏è 1Ô∏è‚É£2Ô∏è‚É£ T√©l√©charger le mod√®le sur votre PC\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Pr√©paration du t√©l√©chargement...\")\n",
    "try:\n",
    "    files.download(MODEL_SAVE_PATH)\n",
    "    files.download(METADATA_PATH)\n",
    "    print(\"‚úÖ T√©l√©chargement lanc√© dans le navigateur !\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors du t√©l√©chargement: {e}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}