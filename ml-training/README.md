# ML Training Pipeline - AI Pictionary

Pipeline d'entraÃ®nement du modÃ¨le CNN pour la reconnaissance de dessins Quick Draw.

## ğŸ“Š Dataset Overview

**Source :** Google Quick Draw Dataset  
**CatÃ©gories :** 20 classes sÃ©lectionnÃ©es  
**Taille :** ~1.4M images (70K par catÃ©gorie)  
**Format brut :** NumPy arrays (.npy files)  
**Format prÃ©traitÃ© :** HDF5 avec compression gzip-4  

### CatÃ©gories (20)

```
apple, sun, tree, house, car,
cat, fish, star, umbrella, flower,
moon, airplane, bicycle, clock, eye,
cup, shoe, cloud, lightning, smiley_face
```

---

## ğŸ”„ Pipeline Workflow

```
1. Download (download_dataset.py)
   â”œâ”€ TÃ©lÃ©charge 20 fichiers .npy depuis Google Cloud Storage
   â”œâ”€ ~3GB de donnÃ©es brutes
   â””â”€ DurÃ©e : 20-30 minutes

2. Preprocess (preprocess_dataset.py)
   â”œâ”€ Charge les .npy files
   â”œâ”€ Applique centroid cropping (alignment)
   â”œâ”€ Normalise [0,1]
   â”œâ”€ Split 80/10/10 (train/val/test)
   â”œâ”€ Sauvegarde en HDF5 compressÃ©
   â””â”€ DurÃ©e : 10 minutes

3. Train (train_model.ipynb)
   â”œâ”€ Charge quickdraw_20cat.h5
   â”œâ”€ Build Simple CNN (35K params)
   â”œâ”€ EntraÃ®ne 15 epochs
   â”œâ”€ Ã‰value sur test set
   â”œâ”€ Sauvegarde backend/models/quickdraw_v1.0.0.h5
   â””â”€ DurÃ©e : 30 minutes
```

---

## ğŸš€ Quick Start

### 1. TÃ©lÃ©charger le Dataset

```bash
cd ml-training
python scripts/download_dataset.py
```

**RÃ©sultat attendu :**
```
data/raw/
â”œâ”€â”€ apple.npy (113 MB)
â”œâ”€â”€ sun.npy (105 MB)
â”œâ”€â”€ tree.npy (98 MB)
...
â””â”€â”€ smiley_face.npy (89 MB)
```

### 2. PrÃ©traiter le Dataset

```bash
python scripts/preprocess_dataset.py
```

**RÃ©sultat attendu :**
```
data/processed/
â””â”€â”€ quickdraw_20cat.h5 (400 MB)
    â”œâ”€ train: 1,120,000 samples
    â”œâ”€ val: 140,000 samples
    â””â”€ test: 140,000 samples
```

### 3. EntraÃ®ner le ModÃ¨le

```bash
jupyter notebook notebooks/train_model.ipynb
```

**Dans le notebook :**
- Menu â†’ Cell â†’ Run All
- Attendre ~30 minutes
- ModÃ¨le sauvegardÃ© dans `../backend/models/quickdraw_v1.0.0.h5`

---

## ğŸ“ Structure du Projet

```
ml-training/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_dataset.py       # TÃ©lÃ©charge 20 catÃ©gories Quick Draw
â”‚   â””â”€â”€ preprocess_dataset.py     # HDF5 + centroid crop + normalize
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ train_model.ipynb         # Jupyter notebook pour entraÃ®nement CNN
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # .npy files (crÃ©Ã© par download)
â”‚   â””â”€â”€ processed/                # quickdraw_20cat.h5 (crÃ©Ã© par preprocess)
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â””â”€â”€ README.md
```

---

## ğŸ§  Model Architecture

**Type :** Simple CNN (Sequential)  
**Input :** 28x28 grayscale images  
**Output :** 20 classes (softmax)  

```python
Model: "simple_cnn"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       
max_pooling2d_1 (MaxPool)   (None, 13, 13, 32)        0         
conv2d_2 (Conv2D)           (None, 11, 11, 64)        18,496    
max_pooling2d_2 (MaxPool)   (None, 5, 5, 64)          0         
flatten (Flatten)           (None, 1600)              0         
dropout (Dropout)           (None, 1600)              0         
dense (Dense)               (None, 20)                32,020    
=================================================================
Total params: 35,836 (140 KB)
Trainable params: 35,836
Non-trainable params: 0
```

**Justification :**
- **2 Conv layers :** Suffisant pour patterns simples (28x28)
- **MaxPooling :** RÃ©duction spatiale progressive
- **Dropout 0.5 :** PrÃ©vention overfitting
- **Taille :** 140KB â†’ Chargement rapide (<50ms)

---

## ğŸ“ˆ Training Configuration

```python
# Hyperparameters
BATCH_SIZE = 128
EPOCHS = 15
LEARNING_RATE = 0.001

# Optimizer
optimizer = Adam(learning_rate=0.001)

# Loss
loss = 'sparse_categorical_crossentropy'

# Metrics
metrics = ['accuracy']

# Callbacks
- EarlyStopping (patience=3, restore_best_weights)
- ReduceLROnPlateau (factor=0.5, patience=2)
```

---

## ğŸ¯ Expected Results

**Target Accuracy :** 91-93% on test set  
**Inference Time :** ~5ms per image  

**Typical Training Curve :**
```
Epoch 1/15  - loss: 0.6234 - accuracy: 0.8156 - val_accuracy: 0.8754
Epoch 5/15  - loss: 0.2891 - accuracy: 0.9045 - val_accuracy: 0.9134
Epoch 10/15 - loss: 0.2156 - accuracy: 0.9234 - val_accuracy: 0.9187
Epoch 15/15 - loss: 0.1934 - accuracy: 0.9312 - val_accuracy: 0.9201
```

**Confusion Matrix :**
- Confusions courantes : `moon â†” sun`, `cat â†” shoe`, `cloud â†” tree`
- DÃ©tails dans le notebook aprÃ¨s entraÃ®nement

---

## ğŸ”¬ Data Preprocessing

### Centroid Cropping

**Pourquoi ?** Aligner les dessins au centre comme dans le dataset Google

**Algorithme :**
```python
1. Calculer centre de masse : (cx, cy)
2. Calculer translation : (dx, dy) = (14 - cx, 14 - cy)
3. Rouler l'image : np.roll(img, (dy, dx), axis=(0, 1))
4. RÃ©sultat : dessin centrÃ© sur (14, 14)
```

**Impact :** +3-5% d'accuracy vs. baseline

### Normalization

```python
# Conversion [0, 255] â†’ [0, 1]
X = X.astype('float32') / 255.0
```

---

## ğŸ“¦ HDF5 Storage Format

**Avantages :**
- âœ… Compression gzip-4 : 1.1GB â†’ 400MB
- âœ… Random access rapide (batch loading)
- âœ… Metadata intÃ©grÃ©e (shape, dtype)

**Structure :**
```
quickdraw_20cat.h5
â”œâ”€ X_train (1120000, 28, 28) - float32
â”œâ”€ y_train (1120000,) - uint8
â”œâ”€ X_val (140000, 28, 28) - float32
â”œâ”€ y_val (140000,) - uint8
â”œâ”€ X_test (140000, 28, 28) - float32
â””â”€ y_test (140000,) - uint8
```

**Lecture efficace :**
```python
import h5py

with h5py.File('quickdraw_20cat.h5', 'r') as f:
    # Lecture batch-wise (Ã©vite RAM overflow)
    batch = f['X_train'][0:128]  # Charge seulement 128 images
```

---

## ğŸ§ª Testing

### Tester le TÃ©lÃ©chargement

```bash
cd ml-training
ls -lh data/raw/*.npy | wc -l  # Devrait afficher 20
```

### Tester le PrÃ©traitement

```bash
python -c "
import h5py
with h5py.File('data/processed/quickdraw_20cat.h5', 'r') as f:
    print('Train samples:', f['X_train'].shape[0])
    print('Val samples:', f['X_val'].shape[0])
    print('Test samples:', f['X_test'].shape[0])
"
```

**RÃ©sultat attendu :**
```
Train samples: 1120000
Val samples: 140000
Test samples: 140000
```

### Tester le ModÃ¨le

```bash
cd ../backend
python -c "
from tensorflow import keras
model = keras.models.load_model('models/quickdraw_v1.0.0.h5')
print('Model loaded successfully!')
print('Input shape:', model.input_shape)
print('Output shape:', model.output_shape)
model.summary()
"
```

---

## ğŸ› Troubleshooting

### Erreur : "No space left on device"

**Cause :** Dataset brut (3GB) + HDF5 (400MB) nÃ©cessitent ~4GB

**Solution :**
```bash
# Nettoyer fichiers .npy aprÃ¨s prÃ©traitement
rm data/raw/*.npy
```

### Erreur : "Out of memory" pendant l'entraÃ®nement

**Cause :** Batch size trop grand pour votre RAM/GPU

**Solution :**
```python
# Dans train_model.ipynb, rÃ©duire BATCH_SIZE
BATCH_SIZE = 64  # Au lieu de 128
```

### TÃ©lÃ©chargement lent

**Cause :** Connexion internet lente

**Solution :**
```bash
# TÃ©lÃ©charger en background avec nohup
nohup python scripts/download_dataset.py > download.log 2>&1 &

# VÃ©rifier progression
tail -f download.log
```

---

## ğŸ“Š Performance Benchmarks

| MÃ©trique | Valeur | Note |
|----------|--------|------|
| Dataset size (raw) | 3.0 GB | 20 Ã— ~150MB |
| Dataset size (HDF5) | 400 MB | Compression gzip-4 |
| Training time | 30 min | Laptop CPU (i5) |
| Training time (GPU) | 10 min | NVIDIA GTX 1060 |
| Model size | 140 KB | TrÃ¨s lÃ©ger |
| Inference time | 5 ms | Temps rÃ©el |
| Memory usage | 2 GB | Pendant training |

---

## ğŸ”„ Active Learning (Phase 2)

Pour amÃ©liorer le modÃ¨le avec les corrections utilisateurs :

1. **RÃ©cupÃ©rer corrections** depuis Firestore
2. **TÃ©lÃ©charger images** depuis Firebase Storage
3. **Merger avec dataset** existant
4. **Fine-tune** le modÃ¨le (freeze Conv layers)
5. **DÃ©ployer** nouvelle version

**Script :** `scripts/retrain_pipeline.py` (TODO)

---

## ğŸ“š References

- [Quick Draw Dataset](https://github.com/googlecreativelab/quickdraw-dataset)
- [TensorFlow Keras API](https://www.tensorflow.org/api_docs/python/tf/keras)
- [HDF5 for Python](https://docs.h5py.org/)

---

**Questions ? Voir `docs/defense_justifications.md` pour explications techniques dÃ©taillÃ©es.**
